{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé• Face Movie Generator (MediaPipe version)\n",
    "\n",
    "Cette application recr√©e l'effet \"Face Movie\" de Picasa directement dans Google Colab.\n",
    "\n",
    "## ‚ú® Nouveaut√©s :\n",
    "- D√©tection de visage via **MediaPipe** (plus fiable que Haar)\n",
    "- Fallback OpenCV Haar si MediaPipe √©choue\n",
    "- Recadrage centr√© sur le visage\n",
    "- Zoom et fondu entre les images\n",
    "- Ajout optionnel de musique\n",
    "- T√©l√©chargement facile de la vid√©o\n",
    "\n",
    "üí° **Utilisation** :\n",
    "1. Ex√©cute toutes les cellules\n",
    "2. Upload tes images et musique\n",
    "3. T√©l√©charge ta vid√©o g√©n√©r√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è Installer les biblioth√®ques n√©cessaires\n",
    "!pip install gradio opencv-python moviepy numpy mediapipe --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import mediapipe as mp\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "# Initialisation MediaPipe & Haar\n",
    "mp_face_detection = mp.solutions.face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.6)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_face(image, size=(640, 640)):\n",
    "    # Conversion en RGB (MediaPipe attend du RGB)\n",
    "    img_rgb = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = img_rgb.shape\n",
    "\n",
    "    # === 1) D√©tection via MediaPipe ===\n",
    "    results = mp_face_detection.process(img_rgb)\n",
    "    if results.detections:\n",
    "        det = results.detections[0]\n",
    "        bbox = det.location_data.relative_bounding_box\n",
    "        x1 = max(int(bbox.xmin * w) - 20, 0)\n",
    "        y1 = max(int(bbox.ymin * h) - 20, 0)\n",
    "        x2 = min(int((bbox.xmin + bbox.width) * w) + 20, w)\n",
    "        y2 = min(int((bbox.ymin + bbox.height) * h) + 20, h)\n",
    "        face_img = image[y1:y2, x1:x2]\n",
    "        face_img = cv2.resize(face_img, size)\n",
    "        return face_img\n",
    "\n",
    "    # === 2) Fallback Haar si MediaPipe √©choue ===\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "    if len(faces) > 0:\n",
    "        x, y, w_box, h_box = max(faces, key=lambda f: f[2]*f[3])\n",
    "        margin = 0.4\n",
    "        x1 = max(int(x - w_box*margin), 0)\n",
    "        y1 = max(int(y - h_box*margin), 0)\n",
    "        x2 = min(int(x + w_box + w_box*margin), image.shape[1])\n",
    "        y2 = min(int(y + h_box + h_box*margin), image.shape[0])\n",
    "        face_img = image[y1:y2, x1:x2]\n",
    "        face_img = cv2.resize(face_img, size)\n",
    "        return face_img\n",
    "\n",
    "    return None\n",
    "\n",
    "def create_face_movie(images, music=None):\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        clips = []\n",
    "        for img in images:\n",
    "            face = detect_face(img)\n",
    "            if face is not None:\n",
    "                clip = ImageClip(face).set_duration(2).resize(lambda t: 1 + 0.03 * t).crossfadein(1)\n",
    "                clips.append(clip)\n",
    "        if not clips:\n",
    "            return \"Aucun visage trouv√©\", None\n",
    "        video = concatenate_videoclips(clips, method=\"compose\")\n",
    "        if music:\n",
    "            video = video.set_audio(AudioFileClip(music.name).set_duration(video.duration))\n",
    "        path = os.path.join(tempdir, \"face_movie.mp4\")\n",
    "        video.write_videofile(path, fps=24, codec=\"libx264\", audio_codec=\"aac\")\n",
    "        return \"Vid√©o pr√™te üéâ\", path\n",
    "\n",
    "# Interface Gradio\n",
    "iface = gr.Interface(\n",
    "    fn=create_face_movie,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Images\", file_types=[\"image\"], file_count=\"multiple\"),\n",
    "        gr.File(label=\"Musique (optionnel)\", file_types=[\"audio\"])\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Text(label=\"Statut\"),\n",
    "        gr.File(label=\"T√©l√©charger la vid√©o\")\n",
    "    ],\n",
    "    title=\"Face Movie (MediaPipe)\",\n",
    "    description=\"Cr√©e un diaporama vid√©o centr√© sur les visages avec MediaPipe ‚Äî compatible iPad\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}