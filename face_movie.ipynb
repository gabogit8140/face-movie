{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé• Face Movie Generator (MediaPipe ‚Äî version stable Colab)\n",
    "\n",
    "D√©tection visage MediaPipe + fallback Haar, musique optionnelle, et sauvegarde vid√©o dans `outputs/`.\n",
    "Interface Gradio pr√™te pour iPadOS + Colab avec bouton t√©l√©chargement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet gradio opencv-python moviepy numpy mediapipe Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import mediapipe as mp\n",
    "from PIL import Image\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
    "import traceback\n",
    "\n",
    "# Initialisation MediaPipe et Haar\n",
    "mp_face_detection = mp.solutions.face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_face(image_rgb, size=(640, 640)):\n",
    "    try:\n",
    "        h, w, _ = image_rgb.shape\n",
    "        img_uint8 = image_rgb.astype(np.uint8)\n",
    "        results = mp_face_detection.process(img_uint8)\n",
    "        if results and results.detections:\n",
    "            det = results.detections[0]\n",
    "            bbox = det.location_data.relative_bounding_box\n",
    "            x1 = max(int(bbox.xmin * w) - 20, 0)\n",
    "            y1 = max(int(bbox.ymin * h) - 20, 0)\n",
    "            x2 = min(int((bbox.xmin + bbox.width) * w) + 20, w)\n",
    "            y2 = min(int((bbox.ymin + bbox.height) * h) + 20, h)\n",
    "            face_img = image_rgb[y1:y2, x1:x2]\n",
    "            face_img = cv2.resize(face_img, size)\n",
    "            return face_img\n",
    "        gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "        if len(faces) > 0:\n",
    "            x, y, w_box, h_box = max(faces, key=lambda f: f[2]*f[3])\n",
    "            margin = 0.4\n",
    "            x1 = max(int(x - w_box*margin), 0)\n",
    "            y1 = max(int(y - h_box*margin), 0)\n",
    "            x2 = min(int(x + w_box + w_box*margin), image_rgb.shape[1])\n",
    "            y2 = min(int(y + h_box + h_box*margin), image_rgb.shape[0])\n",
    "            face_img = image_rgb[y1:y2, x1:x2]\n",
    "            face_img = cv2.resize(face_img, size)\n",
    "            return face_img\n",
    "    except Exception as e:\n",
    "        print('Erreur detect_face:', e)\n",
    "        traceback.print_exc()\n",
    "    return None\n",
    "\n",
    "def create_face_movie(files, music=None, duration_per_face=2.0, zoom=True, transition=1.0):\n",
    "    try:\n",
    "        os.makedirs('outputs', exist_ok=True)\n",
    "        clips = []\n",
    "        processed_count = 0\n",
    "        debug_msgs = []\n",
    "\n",
    "        for file_obj in files:\n",
    "            try:\n",
    "                pil_img = Image.open(file_obj.name).convert('RGB')\n",
    "                img = np.array(pil_img)\n",
    "            except Exception as e:\n",
    "                msg = f'Impossible de lire {getattr(file_obj, \"name\", str(file_obj))}: {e}'\n",
    "                print(msg)\n",
    "                debug_msgs.append(msg)\n",
    "                continue\n",
    "\n",
    "            face = detect_face(img)\n",
    "            if face is None:\n",
    "                msg = f'Pas de visage d√©tect√© dans {os.path.basename(file_obj.name)}'\n",
    "                print(msg)\n",
    "                debug_msgs.append(msg)\n",
    "                continue\n",
    "\n",
    "            clip = ImageClip(face).set_duration(duration_per_face)\n",
    "            if zoom:\n",
    "                clip = clip.resize(lambda t: 1 + 0.03 * t)\n",
    "            clips.append(clip)\n",
    "            processed_count += 1\n",
    "\n",
    "        if processed_count == 0:\n",
    "            return ('Aucun visage d√©tect√© dans les images fournies.\\n' + '\\n'.join(debug_msgs), None, None)\n",
    "\n",
    "        clips_with_fx = []\n",
    "        for i, c in enumerate(clips):\n",
    "            if i == 0:\n",
    "                clips_with_fx.append(c)\n",
    "            else:\n",
    "                clips_with_fx.append(c.crossfadein(transition))\n",
    "\n",
    "        final = concatenate_videoclips(clips_with_fx, method='compose')\n",
    "\n",
    "        if music is not None:\n",
    "            try:\n",
    "                audio_clip = AudioFileClip(music.name)\n",
    "                audio_clip = audio_clip.set_duration(final.duration)\n",
    "                final = final.set_audio(audio_clip)\n",
    "            except Exception as e:\n",
    "                msg = f\"Erreur audio (le fichier audio sera ignor√©) : {e}\"\n",
    "                print(msg)\n",
    "                debug_msgs.append(msg)\n",
    "\n",
    "        out_path = os.path.join('outputs', 'face_movie.mp4')\n",
    "        final.write_videofile(out_path, fps=24, codec='libx264', audio_codec='aac')\n",
    "\n",
    "        status_msg = f'Vid√©o g√©n√©r√©e : {processed_count} visage(s) utilis√©(s).'\n",
    "        if debug_msgs:\n",
    "            status_msg += '\\n' + '\\n'.join(debug_msgs)\n",
    "        return status_msg, out_path, out_path\n",
    "\n",
    "    except Exception as e:\n",
    "        tb = traceback.format_exc()\n",
    "        return f\"Erreur inattendue : {e}\\n\\nTraceback complet :\\n{tb}\", None, None\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=create_face_movie,\n",
    "    inputs=[\n",
    "        gr.File(label='Images (multiple)', file_types=['image'], file_count='multiple'),\n",
    "        gr.File(label='Musique (optionnel)', file_types=['audio'])\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label='Statut', lines=5),\n",
    "        gr.Video(label='Lecture vid√©o'),\n",
    "        gr.File(label='T√©l√©charger la vid√©o')\n",
    "    ],\n",
    "    title='Face Movie (MediaPipe ‚Äî stable)',\n",
    "    description='Uploader images (1+). Musique optionnelle. Colab + iPad friendly.'\n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
  }
 ],
 "metadata": {
  "colab": {
   "name": "Face Movie (MediaPipe) - stable avec t√©l√©chargement",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}