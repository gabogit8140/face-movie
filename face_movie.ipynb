{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install --quiet gradio opencv-python moviepy numpy mediapipe Pillow"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import mediapipe as mp\n",
    "from PIL import Image\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
    "import traceback\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1,\n",
    "                                               refine_landmarks=True, min_detection_confidence=0.5)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def align_face(image_rgb, output_size=(640,640), eye_target=(320,240), ref_eye_dist=120):\n",
    "    try:\n",
    "        h, w, _ = image_rgb.shape\n",
    "        img = image_rgb.astype(np.uint8)\n",
    "        res = mp_face_mesh.process(img)\n",
    "        left_eye = None\n",
    "        right_eye = None\n",
    "        if res and res.multi_face_landmarks:\n",
    "            lm = res.multi_face_landmarks[0].landmark\n",
    "            left_idxs = [33, 133]\n",
    "            right_idxs = [362, 263]\n",
    "            left_eye = np.mean([(lm[i].x * w, lm[i].y * h) for i in left_idxs], axis=0)\n",
    "            right_eye = np.mean([(lm[i].x * w, lm[i].y * h) for i in right_idxs], axis=0)\n",
    "        if left_eye is None or right_eye is None:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "            if len(faces) == 0:\n",
    "                return None\n",
    "            x, y, wb, hb = max(faces, key=lambda f: f[2]*f[3])\n",
    "            cx = x + wb/2\n",
    "            cy = y + hb/3.0\n",
    "            left_eye = np.array([cx - wb*0.18, cy])\n",
    "            right_eye = np.array([cx + wb*0.18, cy])\n",
    "        left_eye = np.array(left_eye, dtype=np.float32)\n",
    "        right_eye = np.array(right_eye, dtype=np.float32)\n",
    "        eyes_center = (left_eye + right_eye) / 2.0\n",
    "        dx = right_eye[0] - left_eye[0]\n",
    "        dy = right_eye[1] - left_eye[1]\n",
    "        current_eye_dist = np.hypot(dx, dy)\n",
    "        if current_eye_dist < 1.0:\n",
    "            return None\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "        scale = ref_eye_dist / current_eye_dist\n",
    "        cx, cy = eyes_center\n",
    "        M = cv2.getRotationMatrix2D((cx, cy), angle, scale)\n",
    "        eyes_center_rot = np.dot(M, np.array([cx, cy, 1.0]))\n",
    "        tx = eye_target[0] - eyes_center_rot[0]\n",
    "        ty = eye_target[1] - eyes_center_rot[1]\n",
    "        M[0,2] += tx\n",
    "        M[1,2] += ty\n",
    "        out_w, out_h = output_size\n",
    "        warped = cv2.warpAffine(img, M, (out_w, out_h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "        return warped\n",
    "    except Exception as e:\n",
    "        print(\"Erreur align_face:\", e)\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def create_face_movie(files, music=None, output_size=(640,640), eye_target=(320,240),\n",
    "                      ref_eye_dist=120, duration_per_face=2.0):\n",
    "    try:\n",
    "        os.makedirs('outputs', exist_ok=True)\n",
    "        clips = []\n",
    "        processed = 0\n",
    "        debug = []\n",
    "        for f in files:\n",
    "            try:\n",
    "                pil = Image.open(f.name).convert('RGB')\n",
    "                img = np.array(pil)\n",
    "            except Exception as e:\n",
    "                msg = f\"Impossible de lire {getattr(f,'name',str(f))}: {e}\"\n",
    "                print(msg); debug.append(msg); continue\n",
    "            aligned = align_face(img, output_size=output_size, eye_target=eye_target, ref_eye_dist=ref_eye_dist)\n",
    "            if aligned is None:\n",
    "                msg = f\"Aucun visage alignable dans {os.path.basename(f.name)}\"\n",
    "                print(msg); debug.append(msg); continue\n",
    "            clip = ImageClip(aligned).set_duration(duration_per_face)\n",
    "            clips.append(clip)\n",
    "            processed += 1\n",
    "        if processed == 0:\n",
    "            return (\"Aucun visage aligné. Détails:\\n\" + \"\\n\".join(debug), None, None)\n",
    "        final = concatenate_videoclips(clips, method='compose')\n",
    "        if music is not None:\n",
    "            try:\n",
    "                audio = AudioFileClip(music.name)\n",
    "                audio = audio.set_duration(final.duration)\n",
    "                final = final.set_audio(audio)\n",
    "            except Exception as e:\n",
    "                msg = f\"Erreur audio (fichier ignoré): {e}\"\n",
    "                print(msg); debug.append(msg)\n",
    "        out_path = os.path.join('outputs', 'face_movie_aligned.mov')\n",
    "        final.write_videofile(out_path, fps=24, codec='libx264', audio_codec='aac',\n",
    "                              ffmpeg_params=[\"-profile:v\",\"baseline\",\"-pix_fmt\",\"yuv420p\"])\n",
    "        status = f\"Vidéo générée : {processed} image(s).\"\n",
    "        if debug:\n",
    "            status += \"\\n\" + \"\\n\".join(debug)\n",
    "        return status, out_path, out_path\n",
    "    except Exception as e:\n",
    "        tb = traceback.format_exc()\n",
    "        return (f\"Erreur inattendue : {e}\\n\\nTraceback:\\n{tb}\", None, None)\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=create_face_movie,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Images (multiple)\", file_types=[\"image\"], file_count=\"multiple\"),\n",
    "        gr.File(label=\"Musique (optionnel)\", file_types=[\"audio\"])\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Statut\", lines=5),\n",
    "        gr.Video(label=\"Lecture vidéo\"),\n",
    "        gr.File(label=\"Télécharger la vidéo\")\n",
    "    ],\n",
    "    title=\"Face Movie — alignement fixe des yeux\",\n",
    "    description=\"Chaque photo est repositionnée/rotated/scalée pour que les yeux soient au même emplacement. Pas de zoom dynamique ni de transitions.\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}