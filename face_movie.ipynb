{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Installer dépendances si besoin\n",
        "!pip install mediapipe moviepy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from moviepy.editor import *\n",
        "from PIL import Image\n",
        "import mediapipe as mp\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "mp_face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True)\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "def align_face_no_zoom(image_rgb, output_size=(1280,720)):\n",
        "    h, w, _ = image_rgb.shape\n",
        "    img = image_rgb.astype(np.uint8)\n",
        "    res = mp_face_mesh.process(img)\n",
        "    \n",
        "    left_eye, right_eye = None, None\n",
        "    if res and res.multi_face_landmarks:\n",
        "        lm = res.multi_face_landmarks[0].landmark\n",
        "        left_idxs = [33, 133]\n",
        "        right_idxs = [362, 263]\n",
        "        left_eye = np.mean([(lm[i].x * w, lm[i].y * h) for i in left_idxs], axis=0)\n",
        "        right_eye = np.mean([(lm[i].x * w, lm[i].y * h) for i in right_idxs], axis=0)\n",
        "    else:\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
        "        if len(faces) == 0:\n",
        "            return None\n",
        "        x, y, wb, hb = max(faces, key=lambda f: f[2]*f[3])\n",
        "        cx = x + wb/2\n",
        "        cy = y + hb/3.0\n",
        "        left_eye = np.array([cx - wb*0.18, cy])\n",
        "        right_eye = np.array([cx + wb*0.18, cy])\n",
        "    left_eye = np.array(left_eye, dtype=np.float32)\n",
        "    right_eye = np.array(right_eye, dtype=np.float32)\n",
        "\n",
        "    eyes_center = (left_eye + right_eye) / 2.0\n",
        "    dx, dy = right_eye[0] - left_eye[0], right_eye[1] - left_eye[1]\n",
        "    angle = np.degrees(np.arctan2(dy, dx))\n",
        "    eye_dist = np.hypot(dx, dy)\n",
        "    if eye_dist < 1.0:\n",
        "        return None\n",
        "\n",
        "    crop_width = eye_dist * 4.0\n",
        "    crop_height = crop_width * (output_size[1] / output_size[0])\n",
        "    center_x, center_y = eyes_center\n",
        "    x1 = int(center_x - crop_width / 2)\n",
        "    y1 = int(center_y - crop_height / 2)\n",
        "    x2 = int(center_x + crop_width / 2)\n",
        "    y2 = int(center_y + crop_height / 2)\n",
        "\n",
        "    if x1 < 0 or y1 < 0 or x2 > w or y2 > h:\n",
        "        M = cv2.getRotationMatrix2D((center_x, center_y), angle, 1.0)\n",
        "        rotated_full = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
        "        final_img = cv2.resize(rotated_full, output_size, interpolation=cv2.INTER_AREA)\n",
        "        return final_img\n",
        "\n",
        "    cropped = img[y1:y2, x1:x2]\n",
        "    crop_h, crop_w = cropped.shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((crop_w/2, crop_h/2), angle, 1.0)\n",
        "    rotated = cv2.warpAffine(cropped, M, (crop_w, crop_h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
        "    final_img = cv2.resize(rotated, output_size, interpolation=cv2.INTER_AREA)\n",
        "    return final_img\n",
        "\n",
        "def create_face_movie(files, duration_per_face=4.0, fade_duration=2.5):\n",
        "    clips = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            pil = Image.open(f.name).convert('RGB')\n",
        "            img = np.array(pil)\n",
        "        except:\n",
        "            continue\n",
        "        aligned = align_face_no_zoom(img)\n",
        "        if aligned is None:\n",
        "            continue\n",
        "        clip = ImageClip(aligned).set_duration(duration_per_face)\n",
        "        clips.append(clip)\n",
        "    if not clips:\n",
        "        return \"Aucune image utilisable\", None\n",
        "    final = clips[0]\n",
        "    for next_clip in clips[1:]:\n",
        "        final = concatenate_videoclips([final.crossfadeout(fade_duration), next_clip.crossfadein(fade_duration)], method='compose')\n",
        "    out_path = 'face_movie_output.mp4'\n",
        "    final.write_videofile(out_path, fps=24, codec='libx264', audio=False)\n",
        "    return f\"Vidéo générée avec {len(clips)} images\", out_path\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Upload images\n",
        "uploaded_files = files.upload()\n",
        "status, video_path = create_face_movie(uploaded_files.values())\n",
        "print(status)\n",
        "if video_path:\n",
        "    from google.colab import files as gfiles\n",
        "    gfiles.download(video_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}