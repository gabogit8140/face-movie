{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui4F3zJ33aAO"
      },
      "execution_count": 3,
      "outputs": [],
      "source": [
        "!pip install moviepy gradio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2, numpy as np, math, random\n",
        "from PIL import Image, ImageOps, ImageDraw\n",
        "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
        "import gradio as gr\n",
        "\n",
        "# === Haar cascade for fallback detection ===\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "\n",
        "validated_points = {}  # {filename: [(x_left,y_left), (x_right,y_right)]}\n",
        "current_file = None\n",
        "clicked_points = []\n",
        "\n",
        "# --- 1. Auto detect eyes (OpenCV only) ---\n",
        "def detect_face_and_eyes(image_rgb):\n",
        "    gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(100,100))\n",
        "    if len(faces)==0: return None\n",
        "    fx, fy, fw, fh = max(faces, key=lambda f: f[2]*f[3])\n",
        "    roi_gray = gray[fy:fy+fh, fx:fx+fw]\n",
        "    roi_color = image_rgb[fy:fy+fh, fx:fx+fw]\n",
        "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "    if len(eyes)>=2:\n",
        "        eyes = sorted(eyes, key=lambda e: e[0])\n",
        "        ex1,ey1,ew1,eh1 = eyes[0]; ex2,ey2,ew2,eh2 = eyes[1]\n",
        "        left_eye = (fx+ex1+ew1//2, fy+ey1+eh1//2)\n",
        "        right_eye = (fx+ex2+ew2//2, fy+ey2+eh2//2)\n",
        "        return {\"left_eye\": left_eye, \"right_eye\": right_eye}\n",
        "    else:\n",
        "        # fallback: estimate from face box\n",
        "        cx = fx+fw/2; eye_y = fy+fh*0.37; sep = fw*0.25\n",
        "        return {\"left_eye\": (int(cx-sep), int(eye_y)), \"right_eye\": (int(cx+sep), int(eye_y))}\n",
        "\n",
        "# --- 2. Preview auto detection (fixed for Gradio) ---\n",
        "def preview_auto(files):\n",
        "    if not files or len(files) == 0:\n",
        "        return None, \"‚ö†Ô∏è No file uploaded\"\n",
        "\n",
        "    # Handle both dict and file-like objects\n",
        "    file = files[0]\n",
        "    path = file[\"name\"] if isinstance(file, dict) else file.name\n",
        "\n",
        "    try:\n",
        "        pil_img = Image.open(path).convert(\"RGB\")\n",
        "        return pil_img, f\"‚úÖ Loaded {os.path.basename(path)}\"\n",
        "    except Exception as e:\n",
        "        return None, f\"‚ùå Error loading image: {e}\"\n",
        "\n",
        "\n",
        "# --- 3. Handle clicks ---\n",
        "def on_click(evt: gr.SelectData):\n",
        "    global clicked_points, current_file\n",
        "    clicked_points.append(evt.index)\n",
        "    if len(clicked_points) > 2:\n",
        "        clicked_points = clicked_points[-2:]\n",
        "    return str(clicked_points)\n",
        "\n",
        "# --- 4. Validate ---\n",
        "def validate_points():\n",
        "    global current_file, clicked_points, validated_points\n",
        "    if current_file and len(clicked_points)==2:\n",
        "        validated_points[current_file] = clicked_points.copy()\n",
        "        return f\"‚úÖ {os.path.basename(current_file)} validated {clicked_points}\"\n",
        "    return \"‚ö†Ô∏è Please select 2 points (eyes).\"\n",
        "\n",
        "# --- 5. Align ---\n",
        "def align_eyes_to_fixed_position(image_rgb, eyes, target_left, target_right, output_size=(1024,768)):\n",
        "    left, right = np.array(eyes[0]), np.array(eyes[1])\n",
        "    center = (left+right)/2.0\n",
        "    t_center = (np.array(target_left)+np.array(target_right))/2.0\n",
        "    angle = math.atan2((right-left)[1], (right-left)[0])\n",
        "    t_angle = math.atan2((target_right-target_left)[1], (target_right-target_left)[0])\n",
        "    rot = t_angle-angle\n",
        "    h,w=image_rgb.shape[:2]\n",
        "    M=cv2.getRotationMatrix2D(tuple(center), math.degrees(rot), 1.0)\n",
        "    rotated=cv2.warpAffine(image_rgb,M,(w,h),flags=cv2.INTER_LANCZOS4,borderValue=(255,255,255))\n",
        "    new_c=np.dot(M,[center[0],center[1],1])\n",
        "    trans=t_center-new_c\n",
        "    M2=np.float32([[1,0,trans[0]],[0,1,trans[1]]])\n",
        "    return cv2.warpAffine(rotated,M2,output_size,flags=cv2.INTER_LANCZOS4,borderValue=(255,255,255))\n",
        "\n",
        "# --- 6. Slideshow ---\n",
        "def create_slideshow(files, music=None, dur=4.0, fade=2.0):\n",
        "    os.makedirs(\"outputs\", exist_ok=True)\n",
        "    clips=[]; out_size=(1024,768)\n",
        "    cx=out_size[0]//2; eye_y=out_size[1]//3; sep=140\n",
        "    FIXED_L=(cx-sep//2,eye_y); FIXED_R=(cx+sep//2,eye_y)\n",
        "    for f in files:\n",
        "        if f.name not in validated_points: continue\n",
        "        pil_img=Image.open(f.name).convert(\"RGB\")\n",
        "        white_bg=Image.new(\"RGB\", pil_img.size,(255,255,255)); white_bg.paste(pil_img,(0,0))\n",
        "        bordered=ImageOps.expand(white_bg,border=30,fill=\"white\")\n",
        "        aligned=align_eyes_to_fixed_position(np.array(bordered), validated_points[f.name], FIXED_L,FIXED_R,out_size)\n",
        "        rotation=random.uniform(-4,4)\n",
        "        clip=ImageClip(aligned).set_duration(dur).rotate(rotation)\n",
        "        clips.append(clip)\n",
        "    if not clips: return \"‚ùå No validated images\", None, None\n",
        "    final=concatenate_videoclips(clips,method=\"compose\",padding=-fade).crossfadein(fade)\n",
        "    if music:\n",
        "        try:\n",
        "            audio=AudioFileClip(music.name).set_duration(final.duration)\n",
        "            final=final.set_audio(audio)\n",
        "        except: pass\n",
        "    out=\"outputs/final_slideshow.mp4\"\n",
        "    final.write_videofile(out,fps=24,codec=\"libx264\",audio_codec=\"aac\",\n",
        "                          ffmpeg_params=[\"-pix_fmt\",\"yuv420p\"],verbose=False,logger=None)\n",
        "    final.close()\n",
        "    return f\"‚úÖ Video created with {len(clips)} validated images\", out, out\n",
        "\n",
        "# === Gradio UI ===\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üëÅÔ∏è Validate eyes before slideshow\")\n",
        "    with gr.Row():\n",
        "        file_in=gr.File(file_types=[\"image\"], file_count=\"multiple\", label=\"üì∏ Photos\")\n",
        "        music_in=gr.File(file_types=[\"audio\"], label=\"üéµ Music (optional)\")\n",
        "    preview_btn=gr.Button(\"üîç Preview first photo\")\n",
        "    img=gr.Image(type=\"pil\", interactive=True, label=\"Click 2 points (eyes)\")\n",
        "    log=gr.Textbox(label=\"Log\")\n",
        "    preview_btn.click(preview_auto, inputs=[file_in], outputs=[img, log])\n",
        "    img.select(on_click, outputs=log)\n",
        "    validate_btn=gr.Button(\"‚úÖ Validate this photo\")\n",
        "    validate_btn.click(validate_points, outputs=log)\n",
        "    dur=gr.Slider(2,8,4,0.5,label=\"Duration per image (s)\")\n",
        "    fade=gr.Slider(1,4,2,0.5,label=\"Fade duration (s)\")\n",
        "    gen_btn=gr.Button(\"üé¨ Generate video\")\n",
        "    out_txt=gr.Textbox()\n",
        "    out_vid=gr.Video()\n",
        "    out_file=gr.File()\n",
        "    gen_btn.click(create_slideshow, inputs=[file_in,music_in,dur,fade], outputs=[out_txt,out_vid,out_file])\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "9_HaS1Zje7oV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}