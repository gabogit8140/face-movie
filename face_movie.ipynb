{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé• Face Movie Generator (MediaPipe ‚Äî version robuste)\n",
    "\n",
    "Notebook Colab pr√™t √† l'emploi : d√©tection MediaPipe (fallback Haar), musique optionnelle, et messages d'erreur clairs.\n",
    "\n",
    "Utilisation : ex√©cute toutes les cellules, upload tes images (1+), puis t√©l√©charge la vid√©o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer les d√©pendances\n",
    "!pip install --quiet gradio opencv-python moviepy numpy mediapipe Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import mediapipe as mp\n",
    "from PIL import Image\n",
    "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
    "from tempfile import TemporaryDirectory\n",
    "import traceback\n",
    "\n",
    "# === Initialisation MediaPipe & Haar ===\n",
    "mp_face_detection = mp.solutions.face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_face(image_rgb, size=(640, 640)):\n",
    "    \"\"\"\n",
    "    image_rgb: numpy array RGB (H, W, 3)\n",
    "    Retourne : face RGB resized ou None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        h, w, _ = image_rgb.shape\n",
    "        # MediaPipe attend RGB uint8\n",
    "        img_uint8 = image_rgb.astype(np.uint8)\n",
    "        results = mp_face_detection.process(img_uint8)\n",
    "        if results and results.detections:\n",
    "            det = results.detections[0]\n",
    "            bbox = det.location_data.relative_bounding_box\n",
    "            x1 = max(int(bbox.xmin * w) - 20, 0)\n",
    "            y1 = max(int(bbox.ymin * h) - 20, 0)\n",
    "            x2 = min(int((bbox.xmin + bbox.width) * w) + 20, w)\n",
    "            y2 = min(int((bbox.ymin + bbox.height) * h) + 20, h)\n",
    "            face_img = image_rgb[y1:y2, x1:x2]\n",
    "            face_img = cv2.resize(face_img, size)\n",
    "            return face_img\n",
    "        # Fallback Haar (convertir en BGR gris pour Haar)\n",
    "        gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "        if len(faces) > 0:\n",
    "            x, y, w_box, h_box = max(faces, key=lambda f: f[2]*f[3])\n",
    "            margin = 0.4\n",
    "            x1 = max(int(x - w_box*margin), 0)\n",
    "            y1 = max(int(y - h_box*margin), 0)\n",
    "            x2 = min(int(x + w_box + w_box*margin), image_rgb.shape[1])\n",
    "            y2 = min(int(y + h_box + h_box*margin), image_rgb.shape[0])\n",
    "            face_img = image_rgb[y1:y2, x1:x2]\n",
    "            face_img = cv2.resize(face_img, size)\n",
    "            return face_img\n",
    "    except Exception as e:\n",
    "        print('Erreur detect_face:', e)\n",
    "        traceback.print_exc()\n",
    "    return None\n",
    "\n",
    "def create_face_movie(files, music=None, duration_per_face=2.0, zoom=True, transition=1.0):\n",
    "    \"\"\"\n",
    "    files: list of uploaded file objects from Gradio\n",
    "    music: uploaded audio file object or None\n",
    "    Retour: (status_message, path_to_video_or_None)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with TemporaryDirectory() as tempdir:\n",
    "            clips = []\n",
    "            processed_count = 0\n",
    "            debug_msgs = []\n",
    "\n",
    "            for idx, file_obj in enumerate(files):\n",
    "                try:\n",
    "                    # Gradio fournit un fichier avec .name ; on ouvre via PIL\n",
    "                    pil_img = Image.open(file_obj.name).convert('RGB')\n",
    "                    img = np.array(pil_img)\n",
    "                except Exception as e:\n",
    "                    msg = f'Impossible de lire {getattr(file_obj, \"name\", str(file_obj))}: {e}'\n",
    "                    print(msg)\n",
    "                    debug_msgs.append(msg)\n",
    "                    continue\n",
    "\n",
    "                face = detect_face(img)\n",
    "                if face is None:\n",
    "                    msg = f'Pas de visage d√©tect√© dans {os.path.basename(file_obj.name)}'\n",
    "                    print(msg)\n",
    "                    debug_msgs.append(msg)\n",
    "                    continue\n",
    "\n",
    "                # MoviePy attend images en RGB numpy\n",
    "                clip = ImageClip(face).set_duration(duration_per_face)\n",
    "                if zoom:\n",
    "                    clip = clip.resize(lambda t: 1 + 0.03 * t)\n",
    "                # Apply crossfadein when concatenating later\n",
    "                clips.append(clip)\n",
    "                processed_count += 1\n",
    "\n",
    "            if processed_count == 0:\n",
    "                return (\"Aucun visage d√©tect√© dans les images fournies.\\n\" + \"\\n\".join(debug_msgs), None)\n",
    "\n",
    "            # Apply crossfade between clips\n",
    "            # We will set crossfadein on each clip except the first when concatenating manually\n",
    "            # Use concatenate_videoclips with method='compose' and then set crossfadein per clip before concatenation\n",
    "            # For simplicity, use the crossfadein method on each clip (MoviePy will handle overlaps)\n",
    "            clips_with_fx = []\n",
    "            for i, c in enumerate(clips):\n",
    "                if i == 0:\n",
    "                    clips_with_fx.append(c)\n",
    "                else:\n",
    "                    clips_with_fx.append(c.crossfadein(transition))\n",
    "\n",
    "            final = concatenate_videoclips(clips_with_fx, method='compose')\n",
    "\n",
    "            # Audio optional\n",
    "            if music is not None:\n",
    "                try:\n",
    "                    audio_clip = AudioFileClip(music.name)\n",
    "                    audio_clip = audio_clip.set_duration(final.duration)\n",
    "                    final = final.set_audio(audio_clip)\n",
    "                except Exception as e:\n",
    "                    # If audio fails, continue without audio but report\n",
    "                    msg = f\"Erreur audio (le fichier audio sera ignor√©) : {e}\"\n",
    "                    print(msg)\n",
    "                    debug_msgs.append(msg)\n",
    "\n",
    "            out_path = os.path.join(tempdir, 'face_movie.mp4')\n",
    "            # Sauvegarde (affiche les logs d'encoding dans la cellule)\n",
    "            final.write_videofile(out_path, fps=24, codec='libx264', audio_codec='aac')\n",
    "\n",
    "            status_msg = f'Vid√©o g√©n√©r√©e : {processed_count} visage(s) utilis√©(s).'\n",
    "            if debug_msgs:\n",
    "                status_msg += '\\n' + '\\n'.join(debug_msgs)\n",
    "            return (status_msg, out_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        tb = traceback.format_exc()\n",
    "        print('Erreur create_face_movie:', e)\n",
    "        print(tb)\n",
    "        return (f'Erreur inattendue : {e}\\nVoir logs pour plus de d√©tails.', None)\n",
    "\n",
    "# === Interface Gradio ===\n",
    "iface = gr.Interface(\n",
    "    fn=create_face_movie,\n",
    "    inputs=[\n",
    "        gr.File(label='Images (multiple)', file_types=['image'], file_count='multiple'),\n",
    "        gr.File(label='Musique (optionnel)', file_types=['audio'])\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label='Statut', lines=5),\n",
    "        gr.File(label='T√©l√©charger la vid√©o')\n",
    "    ],\n",
    "    title='Face Movie (MediaPipe ‚Äî robuste)',\n",
    "    description='Upload images (1+). La musique est optionnelle. Colab + iPad friendly.'\n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Face Movie (MediaPipe) - robust",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}