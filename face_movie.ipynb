{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install --quiet gradio opencv-python moviepy numpy mediapipe Pillow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import mediapipe as mp\n",
        "from PIL import Image, ImageOps\n",
        "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
        "import random\n",
        "\n",
        "# Initialisation des détecteurs de visage et de points de repère faciaux\n",
        "mp_face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5)\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "def align_and_fit_face(image_rgb, output_size=(1280, 720), eye_target=(640, 360)):\n",
        "    \"\"\"\n",
        "    Aligne les yeux sur un point cible tout en s'assurant que l'image entière est visible\n",
        "    dans le cadre de sortie, sans recadrage (zoom < 1).\n",
        "    Note: eye_target est légèrement abaissé pour un meilleur centrage vertical.\n",
        "    \"\"\"\n",
        "    h, w, _ = image_rgb.shape\n",
        "    out_w, out_h = output_size\n",
        "    img_for_detection = image_rgb.astype(np.uint8)\n",
        "\n",
        "    # Détection des yeux avec MediaPipe\n",
        "    res = mp_face_mesh.process(cv2.cvtColor(img_for_detection, cv2.COLOR_BGR2RGB))\n",
        "    left_eye, right_eye = None, None\n",
        "    if res and res.multi_face_landmarks:\n",
        "        lm = res.multi_face_landmarks[0].landmark\n",
        "        left_idxs = [33, 133]\n",
        "        right_idxs = [362, 263]\n",
        "        left_eye = np.mean([(lm[i].x * w, lm[i].y * h) for i in left_idxs], axis=0)\n",
        "        right_eye = np.mean([(lm[i].x * w, lm[i].y * h) for i in right_idxs], axis=0)\n",
        "\n",
        "    # Fallback sur Haar Cascade si MediaPipe échoue\n",
        "    if left_eye is None or right_eye is None:\n",
        "        gray = cv2.cvtColor(img_for_detection, cv2.COLOR_RGB2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
        "        if len(faces) > 0:\n",
        "            x, y, wb, hb = max(faces, key=lambda f: f[2]*f[3])\n",
        "            cx, cy = x + wb/2, y + hb/3.0\n",
        "            left_eye = np.array([cx - wb*0.18, cy])\n",
        "            right_eye = np.array([cx + wb*0.18, cy])\n",
        "\n",
        "    # Si aucun visage n'est détecté, on centre simplement l'image\n",
        "    if left_eye is None or right_eye is None:\n",
        "        scale = min(out_w / w, out_h / h)\n",
        "        new_w, new_h = int(w * scale), int(h * scale)\n",
        "        resized = cv2.resize(image_rgb, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "        final_image = np.full((out_h, out_w, 3), 255, np.uint8)\n",
        "        x_offset = (out_w - new_w) // 2\n",
        "        y_offset = (out_h - new_h) // 2\n",
        "        final_image[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized\n",
        "        return final_image\n",
        "\n",
        "    # Calcul de la transformation\n",
        "    eyes_center = (np.array(left_eye) + np.array(right_eye)) / 2.0\n",
        "    dx, dy = right_eye[0] - left_eye[0], right_eye[1] - left_eye[1]\n",
        "    angle = np.degrees(np.arctan2(dy, dx))\n",
        "    scale = min(out_w / w, out_h / h)\n",
        "    M = cv2.getRotationMatrix2D(tuple(eyes_center), angle, scale)\n",
        "    rotated_eyes_center = np.dot(M, np.array([eyes_center[0], eyes_center[1], 1]))\n",
        "    M[0, 2] += eye_target[0] - rotated_eyes_center[0]\n",
        "    M[1, 2] += eye_target[1] - rotated_eyes_center[1]\n",
        "    \n",
        "    # Appliquer la transformation finale\n",
        "    warped = cv2.warpAffine(image_rgb, M, (out_w, out_h),\n",
        "                            flags=cv2.INTER_LINEAR, \n",
        "                            borderMode=cv2.BORDER_CONSTANT, \n",
        "                            borderValue=(255, 255, 255))\n",
        "    return warped\n",
        "\n",
        "def create_face_movie(files, music=None, duration_per_face=5.0, fade_duration=2.5):\n",
        "    os.makedirs('outputs', exist_ok=True)\n",
        "    clips = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            pil_img = Image.open(f.name).convert('RGBA')\n",
        "        except Exception as e:\n",
        "            print(f\"Impossible d'ouvrir le fichier {f.name}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # --- ORDRE DES OPÉRATIONS CORRIGÉ ---\n",
        "        # 1. Appliquer une inclinaison aléatoire à l'image originale\n",
        "        rot_angle = random.uniform(-5, 5)\n",
        "        tilted_pil = pil_img.rotate(rot_angle, expand=True, resample=Image.BICUBIC)\n",
        "\n",
        "        # 2. Créer un fond blanc et coller l'image inclinée dessus pour gérer la transparence\n",
        "        white_bg = Image.new(\"RGBA\", tilted_pil.size, (255, 255, 255, 255))\n",
        "        white_bg.paste(tilted_pil, (0, 0), tilted_pil)\n",
        "        white_bg = white_bg.convert('RGB')\n",
        "\n",
        "        # 3. Ajouter une bordure blanche épaisse pour l'effet 'photo papier'\n",
        "        bordered_pil = ImageOps.expand(white_bg, border=60, fill='white')\n",
        "\n",
        "        # 4. Convertir en format NumPy pour la détection et l'alignement\n",
        "        img_to_align_np = np.array(bordered_pil)\n",
        "\n",
        "        # 5. Aligner cette nouvelle \"photo-objet\" complète\n",
        "        final_frame_np = align_and_fit_face(img_to_align_np)\n",
        "        if final_frame_np is None:\n",
        "            continue\n",
        "        \n",
        "        clip = ImageClip(final_frame_np).set_duration(duration_per_face)\n",
        "        clips.append(clip)\n",
        "\n",
        "    if not clips:\n",
        "        return \"Aucune image utilisable n'a été traitée.\", None, None\n",
        "\n",
        "    final_clip = concatenate_videoclips(clips, padding=-fade_duration, method=\"compose\")\n",
        "\n",
        "    if music is not None:\n",
        "        try:\n",
        "            audio = AudioFileClip(music.name).set_duration(final_clip.duration)\n",
        "            final_clip = final_clip.set_audio(audio)\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur audio: {e}\")\n",
        "            pass\n",
        "\n",
        "    out_path = 'outputs/movie_aligned_stack_CORRECTED.mp4'\n",
        "    final_clip.write_videofile(out_path, fps=24, codec='libx264', audio_codec='aac', ffmpeg_params=['-pix_fmt', 'yuv420p'])\n",
        "    return f\"Vidéo générée avec {len(clips)} images.\", out_path, out_path\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=create_face_movie,\n",
        "    inputs=[\n",
        "        gr.File(label=\"Images (plusieurs fichiers acceptés)\", file_types=[\"image\"], file_count=\"multiple\"),\n",
        "        gr.File(label=\"Musique (optionnel)\", file_types=[\"audio\"])\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Statut\", lines=5),\n",
        "        gr.Video(label=\"Vidéo Résultat\"),\n",
        "        gr.File(label=\"Télécharger la Vidéo\")\n",
        "    ],\n",
        "    title=\"Créateur de Diaporama Vidéo (Alignement des Yeux)\",\n",
        "    description=\"CORRIGÉ : Applique une bordure et une inclinaison à chaque photo, PUIS aligne le tout pour que les yeux restent fixes. L'image entière est conservée sans recadrage.\",\n",
        "    allow_flagging='never'\n",
        ")\n",
        "iface.launch(share=True, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
